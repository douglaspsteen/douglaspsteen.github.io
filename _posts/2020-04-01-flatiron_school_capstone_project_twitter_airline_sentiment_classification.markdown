---
layout: post
title:      "Flatiron School Capstone Project: Twitter Airline Sentiment Classification"
date:       2020-04-02 02:29:13 +0000
permalink:  flatiron_school_capstone_project_twitter_airline_sentiment_classification
---


In this post, I am providing an overview of my capstone project for the Flatiron School Online Immersive Data Science Bootcamp. I decided to apply NLP and ML to tweets related to the airline industry to build an algorithm that classifies tweets as positive, negative, or neutral. 

For this project, I aimed to answer the following questions: 

1. Which combination of classification algorithm and vectorization method performs best for classifying an airline-related tweet as positive, negative, or neutral?

2. How accurately can this classification be made?

3. Can a large number of unlabeled tweets be used to improve classification accuracy for a set labeled tweets?

Why would we want to apply NLP and machine learning classification to tweets about the airline industry? An efficient and accurate tweet classification system could offer the following advantages:

* Negative tweets can be identified and addressed by appropriate customer service teams

* Positive tweets can be identified and showcased, used to learn what is 'being done right'

* Questions contained within tweets can be identified and addressed by customer service teams

* ...and so on.

## NLP Vectorization Methods
I explored three different NLP vectorization techniques in this project: TF-IDF, Doc2Vec, and GloVe.

### TF-IDF Vectorization

Term Frequency-Inverse Document Frequency (TF-IDF) is a technique used to vectorize words in a corpus of documents. TF-IDF is based on the idea that rare words contain more valuable information for classification than commonly occurring words in the documents. TF-IDF is the product of Term Frequency (TF) and Inverse Document Frequency (IDF), given by the equations below:

![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/TF_equation.png)
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/IDF_equation.png)

### [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)

Doc2Vec is an extension of the Word2Vec algorithm, and is used to create a numeric vector representation of a document, regardless of its length. Document embeddings are learned using the distributed memory or the distributed bag of words models.

### [GloVe](https://nlp.stanford.edu/projects/glove/)

Global Vectors for Word Representation (GloVe) is an unsupervised learning algorithm for generating pre-trained vector representations for words based on co-occurence statistics from a large corpus. For this project, the pre-trained vectors were trained on 2 billion tweets.

## ML Algorithms

In this study, I explored the ability of the following machine learning algorithms to accurately predict whether a tweet is positive, negative, or neutral using features generated by the vectorization techniques described above.

### Linear Support Vector Classification ([LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)) 
LinearSVC is a supervised algorithm that can be used for classification problems. The algorithm predicts test class labels based on decision boundaries that best separate the classes in n-dimensional feature space, using a linear kernel.

### [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
Random Forest is a Decision Tree-based supervised learning ensemble method. Random Forests can be used for classification or regression problems. A Random Forest includes many Decision Trees that each utilize (1) a bootstrap-sampled version of the original dataset and (2) random subsets of the dataset features. In classification problems, each of the Decision Trees in the Random Forest get a 'vote' towards the classification of each example in the test dataset. This method helps counteract the 'overfitting' that can take place when using a single Decision Tree.

### Multinomial Naive Bayes ([Multinomial NB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html))
Naive Bayes classifiers perform probabilistic classification by applying Bayes' Theorem while also assuming that values for a particular feature are independent of values of the other features. Naive Bayes classifiers are commonly used as baseline algorithms for text classification.

### [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)
AdaBoost (short for 'Adaptive Boosting') is a Decision-Tree-based supervised learning ensemble method. AdaBoost can be used for classification or regression problems. An AdaBoost algorithm includes many Decision Trees that are 'weak learners' (i.e., each tree has a depth of 1). Unlike a Random Forest, the trees in AdaBoost are trained sequentially, so that examples that were misclassified in previous trees are more heavily weighted in subsequent trees. This method also helps counteract the 'overfitting' that can take place when using a single Decision Tree

### [XGBoost](https://xgboost.readthedocs.io/en/latest/)
XGBoost (short for eXtreme Gradient Boost) is an extension of the gradient boosting Decision-Tree-based ensemble method. In addition to gradient boosting, XGBoost allows for subsampling of the data at the row, column, and column per split levels, as well as incorporating L1 and L2 regularization.

### [Neural Network](https://keras.io/models/model/)
Neural networks are a set of algorithms that can be used for supervised and unsupervised learning tasks. A neural network consists of an input layer, one or more hidden layers, and an output layer. Neural networks have the advantage of being able to perform 'automatic feature extraction' through the weights and activation functions used in the network.

## Data
I obtained the data for this project from two different sources:
1. 14.6k airline-related tweets labeled as Positive, Negative, Neutral (February 2015)
https://www.kaggle.com/crowdflower/twitter-airline-sentiment

2. 41.5 k unlabeled airline-related tweets (Mar – Feb 2020) from the Twitter Developer API
https://developer.twitter.com/en

## Project Overview
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/project_overview.png)

## Scrubbing
I used the following function to clean all tweets as an initial preprocessing step:
```
def clean_tweet(tweet, stop=False, stem=False):
    """Function to clean tweet text and optionally stem and remove stopwords.
    
    Parameters
    ----------
    tweet : str
        Tweet to be cleaned
    stop : bool
        True to remove stop words (Default = False)
    stem : bool
        True to perform stemming (Default = False)
        
    Returns
    ----------
    Cleaned tweet text
    """
    # Remove punctuation
    tweet = tweet.translate(string.punctuation)
    tweet = tweet.lower().split()
    
    # Option to stem words
    if stem == True:
        stemmer = SnowballStemmer("english")
        tweet = [stemmer.stem(word) for word in tweet]
        
    # Option to remove stop words    
    if stop == True:
        
        # Identify stop words
        stopwords_list = stopwords.words('english')
        punc_list = list(string.punctuation)
        stopwords_list += punc_list
        str_ell_list = ["''", '""', '...', '``']
        stopwords_list += str_ell_list
        
        # Remove stop words
        tweet = [word for word in tweet if word not in stopwords_list]
    
    # Join tweet using whitespace
    tweet = " ".join(tweet)

    # Regex processing
    tweet = re.sub(r"http\S+", "", tweet)
    tweet = re.sub(r"[^A-Za-z0-9^,!.\/'+-=]", " ", tweet)
    tweet = re.sub(r",", " ", tweet)
    tweet = re.sub(r";", " ", tweet)
    tweet = re.sub(r"\.", " ", tweet)
    tweet = re.sub(r"!", "", tweet)
    tweet = re.sub(r":", "", tweet)
    tweet = re.sub(r"\/", " ", tweet)
    tweet = re.sub(r"\^", " ", tweet)
    tweet = re.sub(r"\=", "equals", tweet)
    tweet = re.sub(r"'", "", tweet)
    
    return tweet
```
This function converts all tweet text to lowercase, remove punctuation, and takes care of other messy things like URLs appearing in tweets. The function also contains options to remove stop words and to perform stemming. I decided not to remove stop words for this project, as I did not want to lose any information contained in the tweets (tweets are already limited in length!). I also decided not to perform stemming, as I wanted to maximize all possible matches to the GloVe pre-trained vectors.

After passing tweets through the clean_tweet function, I also:
1. Tokenized all tweets
2. Used LabelEncoder() to generate labels for tweet sentiment classes (‘negative’=0, ‘neutral’=1, ‘positive’=2)
3. Stored X (tweet tokens) and y (tweet labels) for use in other notebooks

```
# Tokenize  text
df['tokens'] = df['clean_text'].map(lambda x: word_tokenize(x)) 

# Perform label encoding
le = LabelEncoder()
le.fit(df['airline_sentiment'])
df['target'] = le.transform(df['airline_sentiment'])

# Store data for use in other notebooks
X_labeled = df.tokens
y_labeled = df.target
%store X_labeled
%store y_labeled
```

## Explore
To explore the data, I visualized the distribution of tweet labels using a bar chart – looks like most of the Twitter traffic concerning airlines is negative!

```
# Quick plot of tweet classes

sns.countplot(x='airline_sentiment', data=df);
```
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_36_0.png)

I also wanted to visualize which words come up most often in positive, negative, and neutral tweets. 

Positive tweets often contain words of gratitude or compliments:

-'thanks', 'thank', 'great', 'love', 'service', 'customer', 'best', 'guys', 'much', 'awesome', 'crew'

```
# Subset tweets to include only positive sentiment
positive = df[df['airline_sentiment'] == 'positive']

for tweet in positive.clean_text:
     positive_list.append(tweet)
		 
positive_text = ' '.join(positive_list)

# Generate the wordcloud object
wordcloud.generate(positive_text)

# plot the wordcloud image                        
plt.figure(figsize = (8, 8), facecolor = None) 
plt.imshow(wordcloud) 
plt.axis("off") 
plt.tight_layout(pad = 0) 
plt.show(); 
```
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_48_0.png)

```
# Visualize distrubution of most common words in positive tweets
fd = FreqDist(word_tokenize(positive_text))
plt.figure(figsize=(12,6))
fd.plot(30, title='Most Common Words in Positive Tweets')
plt.show();
```
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_50_0.png)

Negative tweets often contain words referring to a cancellation or time delay:
-'cancelled', 'service', 'hours', 'hold', 'customer', 'time', 'help', 'plane', 'delay'

![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_55_0.png)
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_57_0.png)

Neutral tweets often contain words signaling a request for information or answer to a question:
-'get', 'please', 'help', 'need', 'us', 'thanks', 'tomorrow', 'dm', 'would', 'flying'

![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_62_0.png)
![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_64_0.png)

## Modeling
For the classification models, I decided to testfour different vectorization techniques: TF-IDF, Doc2Vec, GloVe, and GloVe + Doc2Vec. 

### TF-IDF Vectorization
```
# Define X and y
X = df.clean_text
y = df.target

# Perform train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,
                                                    random_state=1)

# Vectorize data using tfidf vectorizer
vectorizer = TfidfVectorizer(max_features=100)
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)
```
### Doc2Vec Vectorization
```
# Create list of  tokenized tweets
tokens = list(df['tokens'])

# Need to tag data for doc2vec model
tagged_data = [
    TaggedDocument(
        words=tweet, tags=[str(i)])for i, tweet in enumerate(tokens)]

# Instantiate Doc2Vec model and build model vocabulary from tweet data
model = Doc2Vec(vector_size=100, dm=1, epochs=100)
model.build_vocab(tagged_data)

# Train the model on tweets
model.train(tagged_data, total_examples=model.corpus_count,
            epochs=model.epochs)
						
# Now, must use trained model to infer vectors for all kaggle labeled tweets
vecs = []
for tweet in df.tokens:
    vec = model.infer_vector(tweet)
    vecs.append(vec)
vecs = np.array(vecs)

# Define X and y for the d2v models
y = df.target
X = vecs

# Perform train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,
                                                    random_state=1)
```

### GloVe Mean Word Embeddings
```
# Get labeled tweets vocabulary
total_vocabulary = set(word for tweet in df.tokens for word in tweet)

# Get GloVe embeddings for each word present in the vocabulary
# Must open your preferred GloVe file from saved location in local directory
glove = {}
with open(r'C:/Users/dougl/glove.twitter.27B/glove.twitter.27B.200d.txt', 'rb') as f:
    for line in f:
        parts = line.split()
        word = parts[0].decode('utf-8')
        if word in total_vocabulary:
            vector = np.array(parts[1:], dtype=np.float32)
            glove[word] = vector

```
The ```glove``` variable will now contain a vector for each word in ```total_vocabulary``` that was also present in the file from GloVe.

The next step is to use these word embedding vectors to create 'Mean Word Embeddings' for each individual tweet. I do this with the help of the W2vVectorizer class below.

```
class W2vVectorizer(object):
    """Class to generate mean word embeddings from word vectors. This class is
    borrowed from Flatiron School Curriculum Learn.co Mod 6 Section 49"""
    def __init__(self, w2v):
        # Takes in a dictionary of words and vectors as input
        self.w2v = w2v
        if len(w2v) == 0:
            self.dimensions = 0
        else:
            self.dimensions = len(w2v[next(iter(glove))])
    
    # Note: Even though it doesn't do anything, 
    # it's required that this object implement a fit method or else
    # it can't be used in a scikit-learn pipeline  
    def fit(self, X, y):
        return self
            
    def transform(self, X):
        # X should be a series of lists of tokens
        return np.array([
            np.mean([self.w2v[w] for w in words if w in self.w2v]
                   or [np.zeros(self.dimensions)], axis=0) for words in X])
```

```
# Instantiate a mean word embedding vectorizer using glove embeddings
vectorizer = W2vVectorizer(glove)

# Use vectorizer to transform tokenized data to vectors
X_glove = vectorizer.transform(df.tokens)

# Perform train test split on data
X_train, X_test, y_train, y_test = train_test_split(X_glove, y, 
                                                    test_size=0.25, 
                                                    random_state=1)
```

#### GloVe + Doc2Vec

For this vectorization technique, I simply concatenated features generated using the GloVe and Doc2Vec techniques.

```
# Combine GloVe and d2v embeddings for final X dataset

X_g_d2v = np.concatenate((X_glove, X_d2v), axis=1)
```

## ML Classification

For each of these vectorization methods, I tested the following classification algorithms: 

* LinearSVC, Random Forest, Multinomial Naïve Bayes, AdaBoost, XGBoost, Neural Network
	
Below is an example of the code used to train and evaluate a classifier using one vectorizer and one classification algorithm. The function evaluate_clf returns a confusion matrix, classification report, and test accuracy score when passed the test labels and test predictions.

```
def evaluate_clf(y_true, y_pred):
    """Return confusion matrix, classification report, and accuracy score
    for a classifier.
    
    Parameters
    ----------
    y_true : array-like
        Target class labels
    y_pred : array-like
        Predicted class labels
        
    Returns
    ----------
    Confusion matrix, classification report, accuracy score
    """
    
    test_acc = round(accuracy_score(y_true, y_pred), 2)
    
    print('Confusion Matrix:')
    print(confusion_matrix(y_test, y_pred))
    print('---'*20)
    print('Classification Report:')
    print(classification_report(y_test, y_pred))
    print('---'*20)
    print('Test Accuracy:')
    print(test_acc)
```
```
# Instantiate classifier, fit, and predict on test data

svm_clf = LinearSVC(random_state=1)
svm_clf.fit(X_train, y_train)
svm_test_pred = svm_clf.predict(X_test)
```
```
# Evaluate classifier performance

evaluate_clf(y_test, svm_test_pred)
svm_test_acc = round(accuracy_score(y_test, svm_test_pred), 2)
```
```
Confusion Matrix:
[[1757   56   21]
 [ 196  168   16]
 [ 153   44  201]]
------------------------------------------------------------
Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.96      0.89      1834
           1       0.63      0.44      0.52       380
           2       0.84      0.51      0.63       398

    accuracy                           0.81      2612
   macro avg       0.77      0.64      0.68      2612
weighted avg       0.81      0.81      0.80      2612

------------------------------------------------------------
Test Accuracy:
0.81
```
After repeating the above process for each vectorizer and classification algorithm, the results are summarized below:

![](https://raw.githubusercontent.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719/master/tweet_classification_files/tweet_classification_262_0.png)

## Interpretation / Conclusions
The best classification accuracy achieved with respect to whether an airline-related tweet is positive, negative, or neutral is 89%, using either of the following methods:

* Simple Neural Network Classifier using GloVe 200d pre-trained mean word embeddings

* LinearSVC using Glove 200d pre-trained mean word embeddings and Doc2Vec embeddings

Positive tweets often contain words of gratitude or compliments:
'thanks', 'thank', 'great', 'love', 'service', 'customer', 'best', 'guys', 'much', 'awesome', 'crew'

Negative tweets often contain words referring to a cancellation or time delay:
'cancelled', 'service', 'hours', 'hold', 'customer', 'time', 'help', 'plane', 'delay'

Neutral tweets often contain words signaling a request for information or answer to a question:
'get', 'please', 'help', 'need', 'us', 'thanks', 'tomorrow', 'dm', 'would', 'flying'

Some aspects of tweet language are very difficult for NLP/ML classification:

* Sarcasm:

           E.g. "@VirginAmerica husband and I ordered three drinks via my screen and they never came. Awesome!"

* Negative tweets that contain some positive words:

          E.g. "@JetBlue I appreciate the credit for my troubles but the lack of personal response troubles me."
					
## Recommendations
Airline companies should incorporate a twitter sentiment classifier into their customer service plans to more efficiently address customer concerns, questions, opinions, compliments, etc.

NLP can be used to identify words most commonly appearing in positive, negative, and neutral tweets about an airline company. This can provide insight into what a company is doing right and wrong from a customer's perspective.

* Positive: words of gratitude, good customer service
* Negative: words concerning time waiting, delayed/cancelled flights, bad customer service
* Neutral: requests for information, questions

Twitter sentiment classifiers are most effective when using GloVe pre-trained word vectors. Since GloVe vectors are trained on 2 billion tweets, they capture more information than can be obtained by training a Doc2Vec model from scratch on a smaller corpus of unlabeled tweets (~41.5k unlabeled tweets used in this study).

Thanks for reading! The full project repository can be viewed on GitHub [here](https://github.com/douglaspsteen/dsc-capstone-project-v2-online-ds-ft-100719).



